# Data Exploration of OmniMedVQA

## Introduction (TODO)
We are using the dataset OmniMedVQA which contains over 100,000+ images and question answer (qa) items from 73 different medical datasets [@hu2024omnimedvqa]. Examining the dataset finds that the dataset contains [Todo: number of classes for question] classes of questions over all datasets. 

## Dataset Statistics (TODO)
- The types of problem types and number of classes
- The types of modalites and number of
- The number of images in each datset
- 

## Visual Question Answering Examples (TODO)

The two examples of visual question answering from the pulmonary Chest MC dataset.  
![chest-disease-qa](/assets/chest-disease-qa.png)
![chest-imaging-qa](/assets/chest-imaging-qa.png)

The dataset includes diversity in the problem type within each dataset. The first image presents a modality question, which asks about the imaging technique used (such as X-ray, CT, or MRI), while the second image is a disease diagnosis question. All qa items include multiple options relevant to the question posed, the ground truth, and the modality for the image. 

An example from the dataset covid 19 is shown below:
![covid-imaging-qa](/assets/covid-imaging-qa.png)

Different modalities for imaging are used across all datasets but the same problem type can appear across different datasets. 
## Challenges (TODO)

## References

[//]: <> (Will be auto-populated with `pandoc reports/draft_reports/part1_dataexploration.md --citeproc --bibliography=references.bib --csl=ieee.csl  -o deliverables/part1/part1_dataexploration.html`...)
