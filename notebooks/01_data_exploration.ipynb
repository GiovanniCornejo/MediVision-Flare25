{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Multimodal Medical Classification: OmniMedVQA Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook performs **data exploration** on the OmniMedVQA dataset: loading the data, ensuring schema consistency, and analyzing the distribution of question types and modalities. The notebook is structured to serve as both a **working analysis** and a **report**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Detect Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "Use Hugging Face `datasets` library with `load_dataset` and point it at your local JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dir = \"./data/OmniMedVQA/QA_information/Open-access\"\n",
    "json_files = [os.path.join(qa_dir, f) for f in os.listdir(qa_dir) if f.endswith(\".json\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Visualize the Schema\n",
    "\n",
    "(`dataset`, `question_id`, `question_type`, `question`, `gt_answer`, `image_path`, `option_*`, `modality_type`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dir = \"./data/OmniMedVQA/QA_information/Open-access\"\n",
    "json_files = [os.path.join(qa_dir, f) for f in os.listdir(qa_dir) if f.endswith(\".json\")]\n",
    "\n",
    "schema_dict = {}\n",
    "\n",
    "for f in json_files:\n",
    "    try:\n",
    "        df = pd.read_json(f)   # load normally (array of dicts)\n",
    "        schema_dict[os.path.basename(f)] = set(df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "# Show per-file columns\n",
    "for fname, cols in schema_dict.items():\n",
    "    print(f\"\\n{fname} ({len(cols)} columns):\")\n",
    "    print(sorted(cols))\n",
    "\n",
    "# Compare schemas against the \"reference\" (most common set of columns)\n",
    "from collections import Counter\n",
    "\n",
    "# Count frequency of each schema\n",
    "schemas = [tuple(sorted(cols)) for cols in schema_dict.values()]\n",
    "most_common_schema, _ = Counter(schemas).most_common(1)[0]\n",
    "\n",
    "print(\"\\nReference schema:\", most_common_schema)\n",
    "\n",
    "for fname, cols in schema_dict.items():\n",
    "    extra = cols - set(most_common_schema)\n",
    "    missing = set(most_common_schema) - cols\n",
    "    if extra or missing:\n",
    "        print(f\"\\n⚠️ {fname}\")\n",
    "        if extra:\n",
    "            print(\"  Extra columns:\", extra)\n",
    "        if missing:\n",
    "            print(\"  Missing columns:\", missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Note on Schema Inconsistency\n",
    "\n",
    "While inspecting the JSON files, we found that **`Chest CT Scan.json` contains a single entry using the key `\"modality\"` instead of `\"modality_type\"`**.  \n",
    "\n",
    "This would prevent merging all JSON files into a single dataset because Hugging Face requires consistent column names.  \n",
    "\n",
    "Below, we automatically correct this entry so that `\"modality\"` is renamed to `\"modality_type\"` for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"modality\" -> \"modality_type\" in all JSON files if it exists\n",
    "import json\n",
    "\n",
    "for f in json_files:\n",
    "    with open(f, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    modified = False\n",
    "    for entry in data:\n",
    "        if \"modality\" in entry:\n",
    "            entry[\"modality_type\"] = entry.pop(\"modality\")\n",
    "            modified = True\n",
    "    \n",
    "    if modified:\n",
    "        print(f\"Fixed schema in {os.path.basename(f)}\")\n",
    "        # Optionally overwrite the original file\n",
    "        with open(f, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(data, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Create a Unified Dataset\n",
    "\n",
    "(merge across multiple JSONs in `QA_information/Open-access` at minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=json_files, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Analyze Modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Count Samples\n",
    "\n",
    "- Total number of QA items (length of dataset)\n",
    "- Number of unique images\n",
    "- Number of datasets represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "\n",
    "- Distribution of `question_type` (e.g., Anatomy Identification, Modality Classification, etc.)\n",
    "- Distribution of `gt_answer` (top classes, long-tail?)\n",
    "- Dataset-level distribution (are some datasets overrepresented?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Modalities\n",
    "\n",
    "- Count of unique `modality_type` (CT, MRI, X-ray, Ultrasound, etc.)\n",
    "- Visualize counts with bar plots or pie charts\n",
    "- Comment on coverage across modalities (balanced vs skewed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
